{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2e65fc70",
      "metadata": {
        "id": "2e65fc70"
      },
      "source": [
        "# ShopAssistAI 2.0 with Function Calling by AP"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Introduction"
      ],
      "metadata": {
        "id": "pVP7Nxn1BaY_"
      },
      "id": "pVP7Nxn1BaY_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Project Background\n",
        "\n",
        "In today's digital age, online shopping has become the go-to option for many consumers. However, the overwhelming number of choices and the lack of personalized assistance can make the shopping experience daunting. To address this, we have developed. ShopAssist AI, a chatbot that combines the power of large language models and rule-based functions to ensure accurate and reliable information delivery.\n",
        "\n",
        "\n",
        "#### Problem Statement\n",
        "\n",
        "Given a dataset containing information about laptops (product names, specifications, descriptions, etc.), build a chatbot that parses the dataset and provides accurate laptop recommendations based on user requirements."
      ],
      "metadata": {
        "id": "e7TYMV7XA-ae"
      },
      "id": "e7TYMV7XA-ae"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "108f4bac",
      "metadata": {
        "id": "108f4bac"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/upgrad/GenAI_Course_Master/Course_1_ShopAssistAI')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APlrd4dxAFdE",
        "outputId": "62675356-3fc2-4c42-ed0c-cd15e9522aaf"
      },
      "id": "APlrd4dxAFdE",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Approach:\n",
        "\n",
        "1. **Conversation and Information Gathering**: The chatbot will utilize language models to understand and generate natural responses. Through a conversational flow, it will ask relevant questions to gather information about the user's requirements.\n",
        "2. **Information Extraction**: Once the essential information is collected, rule-based functions come into play, extracting top 3 laptops that best matches the user's needs.\n",
        "3. **Personalized Recommendation**: Leveraging this extracted information, the chatbot engages in further dialogue with the user, efficiently addressing their queries and aiding them in finding the perfect laptop solution."
      ],
      "metadata": {
        "id": "Jgmu_WDQBKP2"
      },
      "id": "Jgmu_WDQBKP2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: System Design"
      ],
      "metadata": {
        "id": "ovfx8S28BSHX"
      },
      "id": "ovfx8S28BSHX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset\n",
        "\n",
        "We have a dataset `laptop.csv` where  each row describes the features of a single laptop and also has a small description at the end. The chatbot that we build will leverage LLMs to parse this `Description` column and provide recommendations"
      ],
      "metadata": {
        "id": "IzLsdZxNBQKN"
      },
      "id": "IzLsdZxNBQKN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Workings of the Chatbot"
      ],
      "metadata": {
        "id": "V_leOT9kB5Zu"
      },
      "id": "V_leOT9kB5Zu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chatbot should ask a series of questions to\n",
        "- Determine the user's requirments. For simplicity, we have used 6 features to encapsulate the user's needs. The 6 features are as follows:\n",
        "    - GPU intensity\n",
        "    - Display quality\n",
        "    - Portability\n",
        "    - Multitasking\n",
        "    - Processing speed\n",
        "    - Budget\n",
        "\n",
        "- Confirm if the user's requirements have been correctly captured at the end.\n",
        "\n",
        "After that the chatbot lists down the top 3 products that are the most relevant, and engages in further conversation to help the user find the best one.\n"
      ],
      "metadata": {
        "id": "q0KUiiWEB2OM"
      },
      "id": "q0KUiiWEB2OM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Major functions behind the Chatbot\n",
        "\n",
        "Let's now look at a brief overview of the major functions that form the chatbot. We'll take a deep dive later\n",
        "\n",
        "\n",
        "\n",
        "- `initialize_conversation()`: This initializes the variable conversation with the system message.\n",
        "- `chat_completions_function_calling()`: This takes the ongoing conversation as the input, calls the relevant function from the tools available to it and then returns the response from the assistant.\n",
        "- `moderation_check()`: This checks if the user's or the assistant's message is inappropriate. If any of these is inappropriate, it ends the conversation.\n",
        "- `compare_laptops_with_user()`: This function compares the user's profile with the different laptops and come back with the top 3 recommendations.\n",
        "\n",
        "The existing architecture of ShopAssist 1.0 was modified to leverage the Function Calling API's capabilities for improved performance. Layers which can be removed were identified and existing layers were updated to handle the new approach.\n",
        "\n",
        "The layers that were removed as their purpose was fulfilled by function calling were:\n",
        "- `intent_confirmation_layer()`: This function takes the assistant's response and evaluates if the chatbot has captured the user's profile clearly. Specifically, this checks if the following properties for the user has been captured or not GPU intensity, Display quality, Portability, Multitasking, Processing speed, Budget\n",
        "- `dictionary_present()`: This function checks if the final understanding of user's profile is returned by the chatbot as a python dictionary or not. If there is a dictionary, it extracts the information as a Python dictionary.\n",
        "- `initialize_conv_reco()`: Initializes the recommendations conversation"
      ],
      "metadata": {
        "id": "RAVIF2nZBoY9"
      },
      "id": "RAVIF2nZBoY9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Stage 1`\n",
        "\n",
        "- Intent Clarity Layer\n",
        "\n",
        "`Stage 2`\n",
        "\n",
        "- Product Mapping Layer\n",
        "\n",
        "`Stage 3`\n",
        "\n",
        "- Product Recommendation Layer"
      ],
      "metadata": {
        "id": "gczn5CerMdXw"
      },
      "id": "gczn5CerMdXw"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "85c623ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85c623ea",
        "outputId": "2a10e8ec-c441-4bfc-fc01-3ecf194b220f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.42.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "\n",
        "# Import the libraries\n",
        "import os, json, ast\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "a8353711",
      "metadata": {
        "id": "a8353711"
      },
      "outputs": [],
      "source": [
        "# initialise with the key\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('OpenAI_API_Key')\n",
        "\n",
        "# initialize client\n",
        "client = openai.OpenAI(\n",
        "  api_key=openai.api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Implementation"
      ],
      "metadata": {
        "id": "KBpsVrWVL_L3"
      },
      "id": "KBpsVrWVL_L3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 1"
      ],
      "metadata": {
        "id": "EMGP6CGyIRV4"
      },
      "id": "EMGP6CGyIRV4"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "0c33c213",
      "metadata": {
        "id": "0c33c213"
      },
      "outputs": [],
      "source": [
        "# function to initialize the conversation with the AI assistant\n",
        "# this would be the system message for the api call\n",
        "def initialize_conversation():\n",
        "\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    system_message = f\"\"\"\n",
        "    You are an expert laptop recommendation system. You evaluate requests for laptops based on the following\n",
        "    parameters: GPU intensity, display quality, portability, multitasking, processing speed, and budget.\n",
        "    You need to ask relevant questions to the user in case these points needed are not satisfied\n",
        "    as per the input query.\n",
        "\n",
        "    Based on the input query given by the user, you will need to determine details for the following keys\n",
        "    only: ('gpu intensity', 'display quality', 'portability', 'multitasking', 'processing speed', 'budget').\n",
        "    The values taken in for all the keys as shown above other than budget need to be as per ('low', 'medium', 'high').\n",
        "    The assignment of these values should be based on the importance given by the user for each of the parameters\n",
        "    in consideration. The value for budget needs to be filled in with the actual value as given by the user.\n",
        "\n",
        "    Once you ask the relevant questions and get all the details from the user, your goal is to fetch details of the\n",
        "    top 3 laptops which match the specifications as given by the user by using function calling with\n",
        "    the compare_laptops_with_user function.\n",
        "\n",
        "    {delimiter}\n",
        "    Once you get the list of top 3 laptops you will need to neatly format it and show the recomendations to the\n",
        "    user in the following format:\n",
        "    1. <Laptop name>: <Basic laptop specs in brief>, <price of laptop>\n",
        "    2. <Laptop name>: <Basic laptop specs in brief>, <price of laptop>\n",
        "    3. <Laptop name>: <Basic laptop specs in brief>, <price of laptop>\n",
        "    {delimiter}\n",
        "\n",
        "    {delimiter}\n",
        "    Here are some instructions for the values assigned for the different keys.\n",
        "    If you do not follow this, you'll be heavily penalised.\n",
        "    - The values for all keys, except 'Budget', should strictly be either 'low', 'medium', or 'high' based on\n",
        "    the importance of the corresponding keys, as stated by user.\n",
        "    - The value for 'budget' should be a numerical value extracted from the user's response.\n",
        "    - 'budget' value needs to be greater than or equal to 25000 INR. If the user says less than that,\n",
        "    please mention that there are no laptops in that range and ask them to reconsider or direct them to a live cutomer service agent.\n",
        "    - Do not randomly assign values to any of the keys. The values need to be inferred from the user's response.\n",
        "    - Do not output the python dictionary to the user.\n",
        "    - Do not explicitly ask the user to input the values as low, medium or high. These values should be inferred by you from\n",
        "    the response given by the user for the questions being asked.\n",
        "    - Do not ask the user questions regarding more than 1 parameter. For instance, if the processing speed\n",
        "    requirement and multitasking requirement need to be decided, only ask a question regarding 1 of the parameters first. Refrain from\n",
        "    asking about both the parameters within one question.\n",
        "\n",
        "    {delimiter}\n",
        "\n",
        "    Follow the steps defined below to ensure that you get the required information from the user for all the\n",
        "    parameters:\n",
        "    {delimiter}\n",
        "    Step 1: Greet the user with a short message asking about the type of laptop they need or the purpose for\n",
        "    which they need it.\n",
        "    {delimiter}\n",
        "    Step 2: Based on the input given by the user, try to infer information for the keys as discussed above and\n",
        "    try to fill up the python dictionary only for the keys that are relevant.\n",
        "    {delimiter}\n",
        "    Step 3: In case the response given by the user doesn't satisfactorily cover all the keys of the python dictionary,\n",
        "    then based on the keys that are missed out, ask the user some basic questions to enable them to fill in information\n",
        "    that can help you fill the values for the remaining keys in the dictionary.\n",
        "    {delimiter}\n",
        "    Step 4: Repeat steps 2 and 3 until the python dictionary has all the necessary values filled up with a good level\n",
        "    of confidence. Remember to fill in the values only based on the user's input and don't make any assumptions. Remember to ask simple questions that cover only one parameter at a time.\n",
        "    Do not ask questions regarding more than one parameter at a time.\n",
        "    Confirm that the user has nothing else to add or clarify before moving to the next step.\n",
        "    {delimiter}\n",
        "    Follow the above chain of thoughts.\n",
        "\n",
        "    {delimiter}\n",
        "    A sample conversation with the user can be as follows:\n",
        "    User: \"I am a gamer. What type of laptop would be good for me?\",\n",
        "    Assistant: \"Since you are a gamer is it safe to say that you need a computer that can handle high quality\n",
        "    graphic content? Further, you would also be requiring a good quality display to complement your gaming needs.\",\n",
        "    User: \"Yes, that is correct. I generally play games like GTA 5, Cyberpunk 2077, Call of Duty. However, it is\n",
        "    not important for me to play these games on the highest settings possible. I would even enjoy them with a\n",
        "    medium to high graphics setting.\",\n",
        "    Assistant: \"Thank you for that information, that certainly helps me understand your needs better. Can you give\n",
        "    me some information on whether you would be having a need to carry your laptop around to multiple places or\n",
        "    would you use it primarily at one location?\",\n",
        "    User: \"I don't need to move my laptop around much. I would be mostly playing with the laptop at home only.\",\n",
        "    Assistant: \"Would you be doing a lot of tasks on your computer at the same time? Or is it mostly only going\n",
        "    to be for gaming? This would help me understand your multitasking needs as well as help me to understand the\n",
        "    kind of processor that you require\",\n",
        "    User: \"I generally wouldn't use my laptop for a lot of other purposes than gaming. There is hardly a chance\n",
        "    for me to do multiple things at the same time.\",\n",
        "    Assistant: \"That's great information. Finally, can you please give me some information on the budget that is\n",
        "    on your mind for the laptop?\",\n",
        "    User: \"Below 70000 INR\"\n",
        "\n",
        "    {delimiter}\n",
        "    Here is another sample conversation between the user and assistant:\n",
        "    User: \"Hi, I am an editor.\"\n",
        "    Assistant: \"Great! As an editor, you likely require a laptop that can handle demanding tasks. Hence, the\n",
        "    laptop should have high multitasking capability. You would also need a high end display for better visuals\n",
        "    and editing. May I know what kind of work do you primarily focus on? Are you more involved in video editing,\n",
        "    photo editing, or both? Understanding the specific type of editing work will help me tailor my recommendations\n",
        "    accordingly. Let me know if my understanding is correct until now.\"\n",
        "    User: \"I primarily work with After Effects.\"\n",
        "    Assistant: \"Thank you for providing that information. Working with After Effects involves working with\n",
        "    graphics, animations, and rendering, which will require high GPU. Do you work with high-resolution media\n",
        "    files, such as 4K videos or RAW photos? Understanding your file sizes will help determine the storage capacity\n",
        "    and processing power needed.\"\n",
        "    User: \"Yes, sometimes I work with 4K videos as well.\"\n",
        "    Assistant: \"Thank you for the information. Processing 4K vidoes will require a good processor and high GPU.\n",
        "    I think we have already determined earlier that you need a high GPU. To ensure I have a complete understanding\n",
        "    of your needs, I have one more question: Are you frequently on the go and require a laptop that is lightweight\n",
        "    and easy to carry, or do you primarily work from a stationary location?\"\n",
        "    User: \"Yes, sometimes I travel but do not carry my laptop.\"\n",
        "    Assistant:\"Could you kindly let me know your budget for the laptop? This will help me find options that fit\n",
        "    within your price range while meeting the specified requirements.\"\n",
        "    User: \"my max budget is 1.5lakh inr\"\n",
        "\n",
        "    {delimiter}\n",
        "    Here is another sample conversation between the user and assistant:\n",
        "    User: \"i am a basic business user\"\n",
        "    Assistant: \"As a basic business user, it's important to have a reliable laptop for your day-to-day tasks.\n",
        "    Based on your usage as a basic business user, do you prefer a laptop with a good quality display for\n",
        "    presentations?\"\n",
        "    User: \"yes\"\n",
        "    Assistant: \"Great! Do you prefer a laptop that is easy to carry around or do you primarily use it at a fixed\n",
        "    location?\"\n",
        "    User: \"i need it to be easy to carry around\"\n",
        "    Assistant: \"Thank you for specifying that. Do you often have multiple tasks running on your laptop\n",
        "    simultaneously or primarily focus on one task at a time?\"\n",
        "    User: \"i ususally have multiple tasks running\"\n",
        "    Assistant: \"Thank you for sharing that. Do you prefer a laptop with fast processing speed for quick\n",
        "    performance?\"\n",
        "    User: \"yes i need it to be very quick\"\n",
        "    Assistant: \"Appreciate that input. Finally, what is your budget range for the laptop you are looking to\n",
        "    purchase?\"\n",
        "    User: \"i would like if it is below 1 lakh\"\n",
        "    \"\"\"\n",
        "\n",
        "    conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "\n",
        "    return conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ce4b43ae",
      "metadata": {
        "id": "ce4b43ae"
      },
      "outputs": [],
      "source": [
        "# performs moderation check on user and assisants inputs\n",
        "def moderation_check(user_input):\n",
        "\n",
        "    # Call the OpenAI API to perform moderation on the user's input.\n",
        "    moderation_response = client.moderations.create(input=user_input)\n",
        "\n",
        "    # Extract the moderation result from the API response.\n",
        "    flagged = moderation_response.results[0].flagged\n",
        "\n",
        "    # Check if the input was flagged by the moderation system. If flagged, return \"Flagged\" else return \"Not Flagged\"\n",
        "    return \"Flagged\" if flagged else \"Not Flagged\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Chat Completions API call\n",
        "def get_chat_completions(input, json_format = False):\n",
        "    \"\"\"\n",
        "    Generate chat completions using OpenAI.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        messages = input\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model = MODEL,\n",
        "            messages = messages,\n",
        "            temperature = 0,\n",
        "            response_format = {\"type\": \"json_object\" if json_format else \"text\"}\n",
        "        )\n",
        "\n",
        "        if json_format is False:\n",
        "            response_content = response.choices[0].message.content\n",
        "        else:\n",
        "            response_content = json.loads(response.choices[0].message.content)\n",
        "\n",
        "        return response_content\n",
        "\n",
        "    # Raise exception error\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred with the call to LLM: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "d587d8b3"
      },
      "id": "d587d8b3",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 2"
      ],
      "metadata": {
        "id": "MuEV_3rQIIhS"
      },
      "id": "MuEV_3rQIIhS"
    },
    {
      "cell_type": "code",
      "source": [
        "# given a laptop description as an input extract the json parameters from it\n",
        "def product_map_layer(laptop_description):\n",
        "    delimiter = \"#####\"\n",
        "\n",
        "    lap_spec = {\n",
        "      \"gpu intensity\":\"(Type of the Graphics Processor)\",\n",
        "      \"display quality\":\"(Display Type, Screen Resolution, Display Size)\",\n",
        "      \"portability\":\"(Laptop Weight)\",\n",
        "      \"multitasking\":\"(RAM Size)\",\n",
        "      \"processing speed\":\"(CPU Type, Core, Clock Speed)\"\n",
        "    }\n",
        "\n",
        "    values = {'low','medium','high'}\n",
        "\n",
        "    prompt=f\"\"\"\n",
        "    You are an expert laptop specifications analyst. Your job is to extract the key features of laptops and classify them as per their requirements.\n",
        "    You will be given a paragraph of text as input which represents information\n",
        "    about a laptop. Your task is to extract information for the keys:\n",
        "    'GPU intensity','Display quality','Portability','Multitasking','Processing speed' based on the information\n",
        "    present in the paragraph of text.\n",
        "    {delimiter}\n",
        "    'gpu intensity' must be decided with these rules:\n",
        "    - low: Integrated graphics (e.g., Intel UHD, Intel Iris Plus, AMD Radeon integrated graphics)\n",
        "    - medium: Entry-level to mid-range dedicated graphics (e.g., NVIDIA GTX, AMD Radeon)\n",
        "    - high: High-end dedicated graphics (e.g., NVIDIA RTX, AMD Radeon Pro, NVIDIA Quadro)\n",
        "\n",
        "    'display quality' must be decided with these rules:\n",
        "    - low: Resolution below Full HD (e.g., 1366x768)\n",
        "    - medium: Full HD resolution (1920x1080) or higher\n",
        "    - high: High-resolution display (e.g., 4K, Retina, OLED) with excellent color accuracy and features like HDR support\n",
        "\n",
        "    'portability' must be decided with these rules:\n",
        "    - low: Weighs more than 2.5 kg\n",
        "    - medium: Weighs between 1.5 kg and 2.5 kg\n",
        "    - high: Weighs less than 1.5 kg\n",
        "\n",
        "    'multitasking' must be decided with these rules:\n",
        "    - low: 8GB to 12GB of RAM\n",
        "    - medium: 12GB to 16GB of RAM\n",
        "    - high: 32GB or more of RAM\n",
        "\n",
        "    'processing speed' must be decided with these rules:\n",
        "    - low: Processor clock speed below 2.3 GHz. Should be considered for entry-level processors like Intel Core i3, AMD Ryzen 3\n",
        "    - medium: Processor clock speed between 2.3 GHz and 2.8 GHz. Should be considered for Mid-range processors like Intel Core i5, AMD Ryzen 5\n",
        "    - high: Processor clock speed above 2.8 GHz. Should be considered for High-performance processors like Intel Core i7, AMD Ryzen 7 or higher\n",
        "    {delimiter}\n",
        "\n",
        "    {delimiter}\n",
        "    Here are some example outputs for a better understanding of the task:\n",
        "    input1: \"The Dell Inspiron is a versatile laptop that combines powerful performance and affordability. It features an Intel Core i5 processor clocked at 2.4 GHz, ensuring smooth multitasking and efficient computing. With 8GB of RAM and an SSD, it offers quick data access and ample storage capacity. The laptop sports a vibrant 15.6\" LCD display with a resolution of 1920x1080, delivering crisp visuals and immersive viewing experience. Weighing just 2.5 kg, it is highly portable, making it ideal for on-the-go usage. Additionally, it boasts an Intel UHD GPU for decent graphical performance and a backlit keyboard for enhanced typing convenience. With a one-year warranty and a battery life of up to 6 hours, the Dell Inspiron is a reliable companion for work or entertainment. All these features are packed at an affordable price of 35,000, making it an excellent choice for budget-conscious users.\"\n",
        "    output1: {{'gpu intensity': 'medium','display quality':'medium','portability':'medium','multitasking':'high','processing speed':'medium'}}\n",
        "\n",
        "    input2: \"The Lenovo ThinkPad X1 Carbon is a sleek and lightweight laptop designed for professionals on the go. It is equipped with an Intel Core i7 processor running at 2.6 GHz, providing strong processing capabilities for multitasking and productivity. With 16GB of RAM and an SSD, it offers fast and efficient performance along with ample storage capacity. The laptop features a 14\" IPS display with a resolution of 2560x1440, delivering sharp visuals and accurate colors. It comes with Intel UHD integrated graphics for decent graphical performance. Weighing just 1.13 kg, it is extremely lightweight and highly portable. The laptop features an IR camera for face unlock, providing convenient and secure login options. With a three-year warranty and an impressive battery life of up to 12 hours, the Lenovo ThinkPad X1 Carbon ensures reliability and long-lasting productivity. Priced at 130,000, it offers top-notch performance and portability for professionals.\"\n",
        "    output2: {{'gpu intensity': 'medium', 'display quality': 'high', 'portability': 'high', 'multitasking':'high', 'processing speed':'high'}}\n",
        "\n",
        "    input3: \"The Apple MacBook Pro is a high-end laptop that combines top-tier performance with a stunning display. It is equipped with an Intel Core i9 processor running at 2.9 GHz, providing exceptional processing power for demanding tasks and content creation. With 32GB of RAM and an SSD, it offers seamless multitasking and fast storage access for large projects. The laptop features a 16\" Retina display with a resolution of 3072x1920, delivering breathtaking visuals and precise color reproduction. It comes with an AMD Radeon graphics card, ensuring smooth graphics performance for professional applications. Weighing 2.02 kg, it is relatively lightweight for its size. The laptop features a True Tone display, adjusting the color temperature to match the ambient lighting for a more natural viewing experience. With a three-year warranty and a battery life of up to 10 hours, the Apple MacBook Pro offers reliability and endurance for professionals. Priced at 280,000, it caters to users who require uncompromising performance and a superior display for their demanding workloads.\"\n",
        "    output3: {{'gpu intensity': 'medium', 'display quality': 'high', 'portability': 'medium','multitasking': 'high', 'processing speed': 'high'}}\n",
        "    {delimiter}\n",
        "\n",
        "    ### Strictly don't keep any other text in the values of the JSON dictionary other than low or medium or high ###\n",
        "    \"\"\"\n",
        "\n",
        "    input = f\"\"\"Follow the prompt instructions step-by-step and output the dictionary in JSON format for the\n",
        "    following laptop {laptop_description}.\"\"\"\n",
        "\n",
        "    messages=[{\"role\": \"system\", \"content\":prompt},{\"role\": \"user\",\"content\":input}]\n",
        "    response = get_chat_completions(messages, json_format=True)\n",
        "    return response"
      ],
      "metadata": {
        "id": "4f1db827"
      },
      "id": "4f1db827",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "1f158212",
      "metadata": {
        "id": "1f158212"
      },
      "outputs": [],
      "source": [
        "##Run this code once to extract product info in the form of a dictionary\n",
        "laptop_df= pd.read_csv('laptop_data.csv')\n",
        "\n",
        "## Create a new column \"laptop_feature\" that contains the dictionary of the product features\n",
        "laptop_df['laptop_feature'] = laptop_df['Description'].apply(lambda x: product_map_layer(x))\n",
        "\n",
        "# all the updated data is now being stored inside updated_laptop.csv\n",
        "laptop_df.to_csv(\"updated_laptop.csv\",index=False,header = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "8fbda603",
      "metadata": {
        "id": "8fbda603"
      },
      "outputs": [],
      "source": [
        "def compare_laptops_with_user(user_req_string):\n",
        "    # read the updated laptop csv file with the added parameter json information\n",
        "    laptop_df = pd.read_csv('updated_laptop.csv')\n",
        "\n",
        "    # understand budget from the users requirement input dict\n",
        "    user_requirements = user_req_string\n",
        "    user_budget = int(user_requirements.get('budget', '0'))\n",
        "\n",
        "    # make a copy of the df and format the prices to a numeric value\n",
        "    filtered_laptops = laptop_df.copy()\n",
        "    filtered_laptops['Price'] = filtered_laptops['Price'].str.replace(',', '').astype(int)\n",
        "    filtered_laptops = filtered_laptops[filtered_laptops['Price'] <= user_budget].copy()\n",
        "\n",
        "    # # # Mapping string values 'low', 'medium', 'high' to numerical scores 0, 1, 2\n",
        "    mappings = {'low': 0, 'medium': 1, 'high': 2}\n",
        "\n",
        "    # # # Creating a new column 'Score' in the filtered DataFrame and initializing it to 0\n",
        "    filtered_laptops['Score'] = 0\n",
        "\n",
        "    # generate scores for each laptop\n",
        "    for index, row in filtered_laptops.iterrows():\n",
        "        # read the laptop_feature string which contains the json pertaining to the laptop and convert it to a dict\n",
        "        user_product_match_str = row['laptop_feature']\n",
        "        laptop_dict = ast.literal_eval(user_product_match_str)\n",
        "\n",
        "        # converting keys to lowercase\n",
        "        laptop_dict = {k.lower(): v for k,v in laptop_dict.items()}\n",
        "\n",
        "        score = 0\n",
        "\n",
        "        for key, user_value in user_requirements.items():\n",
        "            if key.lower() == 'budget':\n",
        "                continue\n",
        "            laptop_value = laptop_dict.get(key.lower(), None)\n",
        "            if laptop_value is not None:\n",
        "                laptop_mapping = mappings.get(laptop_value.lower(), -1)\n",
        "            else:\n",
        "                laptop_mapping = -1\n",
        "            user_mapping = mappings.get(user_value.lower(), -1)\n",
        "            if laptop_mapping >= user_mapping:\n",
        "                # if the laptop value is greater than or equal to the user value the score is incremented by 1\n",
        "                score += 1\n",
        "\n",
        "        filtered_laptops.loc[index, 'Score'] = score\n",
        "\n",
        "    # sort the laptops by score in descending order and return the top 5 products\n",
        "    top_laptops = filtered_laptops.drop('laptop_feature', axis=1)\n",
        "    top_laptops = top_laptops.sort_values('Score', ascending=False).head(3)\n",
        "\n",
        "    return top_laptops.to_json(orient='records')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 3\n",
        "\n",
        "Using the Function Calling capability of OpenAI to trigger specific functions based on the input of the user."
      ],
      "metadata": {
        "id": "jMGJA_sBI8fm"
      },
      "id": "jMGJA_sBI8fm"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "8beb3d47",
      "metadata": {
        "id": "8beb3d47"
      },
      "outputs": [],
      "source": [
        "def get_chat_completions_function_calling(input):\n",
        "\n",
        "    model = 'gpt-4o-mini'\n",
        "\n",
        "    # describing the function call parameters\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"compare_laptops_with_user\",\n",
        "                \"description\": \"Get the top 3 laptops for the user from the catalogue available based on parameters like GPU intensity, display quality, portability, multitasking, processing speed, and budget\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"gpu intensity\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The GPU intensity requirement of the user specified as low, medium or high\"\n",
        "                        },\n",
        "                        \"display quality\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The Display Quality requirement of the user specified as low, medium or high\"\n",
        "                        },\n",
        "                        \"portability\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The Portability requirement of the user specified as low, medium or high\"\n",
        "                        },\n",
        "                        \"multitasking\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The Multitasking requirement of the user specified as low, medium or high\"\n",
        "                        },\n",
        "                        \"processing speed\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The Processing speed requirement of the user specified as low, medium or high\"\n",
        "                        },\n",
        "                        \"budget\": {\n",
        "                            \"type\": \"integer\",\n",
        "                            \"description\": \"The maximum budget of the user\"\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\n",
        "                        \"GPU intensity\",\n",
        "                        \"Display quality\",\n",
        "                        \"Portability\",\n",
        "                        \"Multitasking\",\n",
        "                        \"Processing speed\",\n",
        "                        \"Budget\"\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "    try:\n",
        "        messages = input\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model = model,\n",
        "            messages = messages,\n",
        "            temperature = 0,\n",
        "            tools = tools,\n",
        "            tool_choice = 'auto'\n",
        "        )\n",
        "\n",
        "        # check if the model wanted to call a function\n",
        "        tool_calls = response.choices[0].message.tool_calls\n",
        "\n",
        "        # call the function\n",
        "        if tool_calls:\n",
        "            available_functions = {\n",
        "                \"compare_laptops_with_user\": compare_laptops_with_user,\n",
        "            }\n",
        "\n",
        "            # append response given by gpt to input messages list\n",
        "            messages.append(response.choices[0].message)\n",
        "\n",
        "            for tool_call in tool_calls:\n",
        "                function_name = tool_call.function.name\n",
        "                function_to_call = available_functions[function_name]\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "                function_response = function_to_call(function_args)\n",
        "\n",
        "                function_call_response_dict = {\n",
        "                    \"tool_call_id\": tool_call.id,\n",
        "                    \"role\": \"tool\",\n",
        "                    \"name\": function_name,\n",
        "                    \"content\": function_response,\n",
        "                }\n",
        "\n",
        "                # append response_messages to the original input messages\n",
        "                messages.append(function_call_response_dict)\n",
        "\n",
        "                # make a second call to the model\n",
        "                second_response = client.chat.completions.create(\n",
        "                    model = model,\n",
        "                    messages = messages,\n",
        "                    temperature = 0\n",
        "                )\n",
        "\n",
        "                second_response_message = [{\"role\": \"assistant\", \"content\": second_response.choices[0].message.content}]\n",
        "                return second_response_message\n",
        "        else:\n",
        "            response_message = [{\"role\": \"assistant\", \"content\": response.choices[0].message.content}]\n",
        "            return response_message\n",
        "\n",
        "    # Raise exception error\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dialogue Management System\n",
        "\n",
        "Bringing everything together, we create a `dialogue_mgmt_system()` function that contains the logic of how the different layers would interact with each other. This will be the function that we'll call to initiate the chatbot"
      ],
      "metadata": {
        "id": "ZEf6eYZKJWii"
      },
      "id": "ZEf6eYZKJWii"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "d38d8dee",
      "metadata": {
        "id": "d38d8dee"
      },
      "outputs": [],
      "source": [
        "def dialogue_mgmt_system():\n",
        "    # initialize the conversation\n",
        "    conversation = initialize_conversation()\n",
        "\n",
        "    print(\"Assistant:\\nHow may I help you with your laptop selection?\\n\")\n",
        "\n",
        "    user_input = ''\n",
        "\n",
        "    while user_input.lower() != 'exit':\n",
        "        print(\"User: \")\n",
        "        user_input = input()\n",
        "\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"\\nAssistant:\\nThank you for using this service. Please do not hesitate to contact us if you need assistance. See you soon!\\n\")\n",
        "            break\n",
        "\n",
        "        conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "        response = get_chat_completions_function_calling(conversation)\n",
        "\n",
        "        print(\"\\nAssistant:\\n\", response[0]['content'], '\\n')\n",
        "\n",
        "        conversation += response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "009319b2",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "009319b2",
        "outputId": "10309651-59f8-4613-ff3c-4d809c4a8dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant:\n",
            "How may I help you with your laptop selection?\n",
            "\n",
            "User: \n",
            "gaming laptop\n",
            "\n",
            "Assistant:\n",
            " Great! Since you're looking for a gaming laptop, it's important to have a machine that can handle high-quality graphics and provide a smooth gaming experience. \n",
            "\n",
            "To better understand your needs, could you please tell me how important GPU intensity is for you? Do you want to play games on high settings, or are medium settings sufficient? \n",
            "\n",
            "User: \n",
            "not sure\n",
            "\n",
            "Assistant:\n",
            " No problem! Let's explore this a bit more. What types of games do you typically play? Are they graphically demanding games like AAA titles, or do you play less demanding games? This will help me gauge your GPU intensity needs. \n",
            "\n",
            "User: \n",
            "less demanding like minecraft\n",
            "\n",
            "Assistant:\n",
            " Thank you for that information! Since you play less demanding games like Minecraft, we can categorize your GPU intensity requirement as low.\n",
            "\n",
            "Next, let's talk about display quality. How important is it for you to have a good quality display for your gaming experience? Would you prefer a high-quality display, or is a standard display sufficient for your needs? \n",
            "\n",
            "User: \n",
            "no\n",
            "\n",
            "Assistant:\n",
            " Got it! So, a standard display quality is sufficient for your gaming needs. I will categorize your display quality requirement as low.\n",
            "\n",
            "Now, let's discuss portability. Will you be carrying your laptop around often, or will you primarily use it in one location? How important is it for you to have a lightweight and portable laptop? \n",
            "\n",
            "User: \n",
            "yea\n",
            "\n",
            "Assistant:\n",
            " Thank you for clarifying! Since portability is important to you, I will categorize your portability requirement as high.\n",
            "\n",
            "Next, let's talk about multitasking. Will you be using your laptop for multiple tasks at the same time, or will it mainly be for gaming? How important is multitasking capability for you? \n",
            "\n",
            "User: \n",
            "yea\n",
            "\n",
            "Assistant:\n",
            " Thank you for that information! Since multitasking is important to you, I will categorize your multitasking requirement as medium.\n",
            "\n",
            "Now, let's discuss processing speed. Do you prefer a laptop with fast processing speed for quick performance, or is a standard speed sufficient for your gaming and other tasks? \n",
            "\n",
            "User: \n",
            "no\n",
            "\n",
            "Assistant:\n",
            " Understood! A standard processing speed is sufficient for your needs, so I will categorize your processing speed requirement as low.\n",
            "\n",
            "Finally, could you please let me know your budget for the laptop? This will help me find options that fit within your price range while meeting your specified requirements. \n",
            "\n",
            "User: \n",
            "50000\n",
            "\n",
            "Assistant:\n",
            " Here are the top 3 laptop recommendations based on your requirements:\n",
            "\n",
            "1. **Acer Swift 3**: Ryzen 5 processor (2.3 GHz), 8GB RAM, 14\" IPS display (1920x1080), AMD Radeon graphics, lightweight at 1.2 kg, great for portability, priced at 50,000 INR.\n",
            "\n",
            "2. **Dell Inspiron**: Intel Core i5 processor (2.4 GHz), 8GB RAM, 15.6\" LCD display (1920x1080), Intel UHD graphics, weighs 2.5 kg, good for everyday use, priced at 35,000 INR.\n",
            "\n",
            "3. **Lenovo IdeaPad**: Intel Core i3 processor (2.1 GHz), 8GB RAM, 15.6\" TN display (1366x768), Intel UHD graphics, weighs 2.2 kg, suitable for basic tasks, priced at 25,000 INR.\n",
            "\n",
            "Let me know if you need any more information or assistance! \n",
            "\n",
            "User: \n",
            "exit\n",
            "\n",
            "Assistant:\n",
            "Thank you for using this service. Please do not hesitate to contact us if you need assistance. See you soon!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the function to start the dialogue management system\n",
        "dialogue_mgmt_system()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}